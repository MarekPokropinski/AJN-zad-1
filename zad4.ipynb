{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm.auto import tqdm, trange\n",
    "import requests\n",
    "import xml.etree.ElementTree as et\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB, CategoricalNB, BernoulliNB, GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate XMLs with KRNNT tagger (localhost:9003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_texts(dirname):\n",
    "    filenames = glob.glob(dirname+'/*/*.txt')\n",
    "    for filename in tqdm(filenames):\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            r = requests.post('http://localhost:9003?output_format=XCES', data=f.read().encode('utf-8'))\n",
    "        with open(filename.replace('.txt', '.xml'), 'w', encoding='utf-8') as f:\n",
    "            f.write(r.text)\n",
    "            \n",
    "#tag_texts('wiki_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load flexems translation to wordclasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordclass_dict = {}\n",
    "with open('fleksemy.csv', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split(',')\n",
    "        wordclass_dict[line[1]] = line[3].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load xmls into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dirname):\n",
    "    datasets = {'rzeczownik':[], 'czasownik':[], 'przymiotnik':[]}\n",
    "    filenames = glob.glob(dirname+\"/*.xml\")\n",
    "    for filename in tqdm(filenames):\n",
    "        tags_list = []\n",
    "        root = et.parse(filename).getroot()\n",
    "        for x in root.findall('chunk/sentence/tok/lex') + root.findall('chunkList/chunk/chunk/tok/lex'):\n",
    "            if x.get('disamb') == '1':\n",
    "                base = x.find('base').text.split(':')[0]\n",
    "                tag = x.find('ctag').text.split(':')[0]\n",
    "                wordclass = wordclass_dict[tag]\n",
    "                tags_list.append((base, wordclass))\n",
    "\n",
    "        category = filename.split('\\\\')[1].split('_')[0]\n",
    "        for key in datasets:\n",
    "            datasets[key].append((category, [base for base, wordclass in tags_list if wordclass == key]))\n",
    "    return datasets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf249499917a4148a172ba015ce22219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6fc226c00a54c998e67db577d2298f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset('wiki_data/cmc_train')\n",
    "test_ds = load_dataset('wiki_data/cmc_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trivial bag of words and NaiveBayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rzeczownik\n",
      "building dictionary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492deb720a8d4d1aabaa9d0827c8c462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('rok', 18302), ('miejsce', 4473), ('to', 3780), ('czas', 3560), ('Polska', 2944), ('bibliografia', 2873), ('samolot', 2812), ('świat', 2720), ('co', 2663), ('wersja', 2471)]\n",
      "dictionary length:  5000\n",
      "defining datasets as BoW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2caf5ce8032f40778204ad4e7a826b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99581cc0cb54aa19eeecc35a6996c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(6886, 5000) (6886,) (2953, 5000) (2953,)\n",
      "czasownik\n",
      "building dictionary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a724196102e455fa32286d539b50bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('być', 30993), ('zostać', 9332), ('mieć', 4995), ('móc', 3430), ('występować', 1958), ('znajdować', 1853), ('prowadzić', 1557), ('posiadać', 1423), ('stosować', 1360), ('należeć', 1326)]\n",
      "dictionary length:  5000\n",
      "defining datasets as BoW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1b25eff30b4e46abe44e585317df3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd0fa87c2e94673be43126083c600ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(6886, 5000) (6886,) (2953, 5000) (2953,)\n",
      "przymiotnik\n",
      "building dictionary\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae67e740de294e52aba1ac227c7c44ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[('który', 11410), ('ten', 10605), ('pierwszy', 5041), ('polski', 4730), ('swój', 3886), ('jeden', 3559), ('inny', 3504), ('duży', 3004), ('zewnętrzny', 2762), ('nowy', 2725)]\n",
      "dictionary length:  5000\n",
      "defining datasets as BoW\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f8a382b7ad45cf908604d277ab5811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6886.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388c0898c0b045b1ae9554743a4125ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2953.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(6886, 5000) (6886,) (2953, 5000) (2953,)\n"
     ]
    }
   ],
   "source": [
    "dict_size = 5000\n",
    "\n",
    "bow = {}\n",
    "for key in train_ds:\n",
    "    print(key)\n",
    "    \n",
    "    print('building dictionary')\n",
    "    dictionary = {}\n",
    "    for _, words in tqdm(train_ds[key]):\n",
    "        for word in words:\n",
    "            if word not in dictionary:\n",
    "                dictionary[word] = 1\n",
    "            else:\n",
    "                dictionary[word] += 1\n",
    "                \n",
    "    # dict reducing - only N most frequent words\n",
    "    dictionary = sorted(dictionary.items(), key = lambda x: x[1], reverse=True)[:dict_size]\n",
    "    print(dictionary[:10])\n",
    "    dictionary = {key: value for key, value in dictionary}\n",
    "    print('dictionary length: ', len(dictionary))\n",
    "    \n",
    "    print('defining datasets as BoW')\n",
    "    train_X = np.array([[1. if word in words else 0. for word in dictionary] for _, words in tqdm(train_ds[key])])\n",
    "    _, train_y = np.unique(np.array([category for category, _ in train_ds[key]]), return_inverse=True)\n",
    "    \n",
    "    test_X = np.array([[1. if word in words else 0. for word in dictionary] for _, words in tqdm(test_ds[key])])\n",
    "    _, test_y = np.unique(np.array([category for category, _ in test_ds[key]]), return_inverse=True)\n",
    "    \n",
    "    print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "    bow[key] = (train_X, train_y, test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rzeczownik 0.9236131280859715 0.8645445309854385\n",
      "czasownik 0.7492012779552716 0.5980358956992888\n",
      "przymiotnik 0.8621841417368574 0.7660006772773451\n"
     ]
    }
   ],
   "source": [
    "for key, (train_X, train_y, test_X, test_y) in bow.items():\n",
    "    cnb = MultinomialNB()\n",
    "    cnb.fit(train_X, train_y)\n",
    "    train_score = cnb.score(train_X, train_y)\n",
    "    test_score = cnb.score(test_X, test_y)\n",
    "    print(key, train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
